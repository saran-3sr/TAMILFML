{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1 a Dataset creation"
      ],
      "metadata": {
        "id": "xADMrVRWtER3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ74cKQttAvz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "arr=np.array([['mango',2,50],['orange',5,60],['apple',10,70]])\n",
        "df=pd.DataFrame(arr,columns=['Fruit Name','Kg','Cost per Kg'])\n",
        "print(df)\n",
        "df['Total Cost']=df['Kg'].astype(int)*df['Cost per Kg'].astype(int)\n",
        "print(df)\n",
        "df.to_csv('fruits.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 b Random data set creation and visualization"
      ],
      "metadata": {
        "id": "8LDDAQZ-tLQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df= pd.DataFrame({\"Match_Number\" : range(1,11),\n",
        "                     \"No_of_sixes\"  : np.random.randint(5, 20, size=10),\n",
        "                     \"No_of_fours\"  : np.random.randint(5, 30, size=10)\n",
        "                     })\n",
        "print(df)\n",
        "df.to_csv('sport.csv')\n",
        "plt.plot(df['Match_Number'],df[ \"No_of_sixes\"]) \n",
        "plt.bar(df['Match_Number'],df[ \"No_of_fours\"], color ='maroon',width = 0.4)\n",
        "plt.scatter(df['Match_Number'],df[ \"No_of_sixes\"]) \n",
        "plt.xlabel('Match_Number')\n",
        "plt.ylabel('No_of_sixes')\n",
        "plt.pie(df[\"No_of_fours\"],labels=df['Match_Number'])\n",
        "plt.legend(title = \"No of sixes in each match\")"
      ],
      "metadata": {
        "id": "58FPXIoltcNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 a Implementation of Simple linear regression"
      ],
      "metadata": {
        "id": "Vt2wxk1TtloN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pandas as p\n",
        "\n",
        "\n",
        "\n",
        "df = p.read_csv(\"stadium.csv\")\n",
        "x = df[\"price\"].tolist()[:160]\n",
        "y = df[\"area\"].tolist()[:160]\n",
        "\n",
        "sum_x = sum(x)\n",
        "sum_y = sum(y)\n",
        "xy = []\n",
        "def square_list(x):\n",
        "    return x*x\n",
        "for a in range(len(x)):\n",
        "    pro = x[a]*y[a]\n",
        "    xy.append(pro)\n",
        "sum_xy = sum(xy)\n",
        "sum_x_squared = sum(list(map(square_list,x)))\n",
        "a = (len(x) * sum_xy - sum_x * sum_y) / (len(x) * sum_x_squared - sum_x ** 2)\n",
        "b = (sum_y - a * sum_x) / len(x)\n",
        "\n",
        "y_pred = [a*x[i] + b for i in range(len(x))]\n",
        "\n",
        "\n",
        "x_test = df[\"price\"].tolist()[160:200]\n",
        "y_test = df[\"area\"].tolist()[160:200]\n",
        "\n",
        "\n",
        "y_test_pred = [a * x_test[i] + b for i in range(len(x_test))] \n",
        "numerator=sum((y_test[i] - y_test_pred[i])**2 for i in range(len(x_test)))\n",
        "denominator=sum((y_test[i] - sum(y_test) / len(x_test))**2 for i in range(len(x_test)))\n",
        "\n",
        "\n",
        "accuracy = numerator / denominator\n",
        "rmse = math.sqrt(sum((y_test[i] - y_test_pred[i]) ** 2 for i in range(len(x_test))) / len(x_test))\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"RMSE: \",rmse)\n",
        "\n",
        "\n",
        "plt.scatter(x, y, color='red')\n",
        "plt.scatter(x_test, y_test, color='green')\n",
        "plt.plot(x, y_pred, color='black', linewidth=2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Plpxjyvttmpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 b Simple Linear Regression using inbuilt libraries"
      ],
      "metadata": {
        "id": "s9JBC59guLuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split  \n",
        "import matplotlib.pyplot as mtp \n",
        "from scipy import stats\n",
        "\n",
        "df = pd.read_csv(\"stadium.csv\")\n",
        "x = np.array(df[\"price\"])\n",
        "y = np.array(df[\"area\"])\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0) \n",
        "slope,intercept,r,p,std_err=stats.linregress(x_test,y_test)\n",
        "\n",
        "def myfunc(x):\n",
        "    return slope*x+intercept\n",
        "\n",
        "model=LinearRegression()\n",
        "model.fit(x.reshape(-1,1),y)\n",
        "\n",
        "mymodel=list(map(myfunc,x_test))\n",
        "\n",
        "y_pred= model.predict(x_test.reshape(-1,1))  \n",
        "x_pred= model.predict(x_train.reshape(-1,1))  \n",
        "mtp.scatter(x_train, y_train, color=\"green\") \n",
        "mtp.scatter(x_test,y_test,color='blue')  \n",
        "mtp.plot(x_test, mymodel, color=\"red\")    \n",
        "mtp.title(\"price vs area\")  \n",
        "mtp.xlabel(\"area\")  \n",
        "mtp.ylabel(\"price\")  \n",
        "print(\"Correlation coefficient: \",r)\n",
        "print(\"P_value: \",p)\n",
        "print(\"Standard error: \",std_err)\n",
        "mtp.show()   "
      ],
      "metadata": {
        "id": "9Nl0vOaquNCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 a Implement classification without using inbuilt libraries"
      ],
      "metadata": {
        "id": "LFljGXIivFw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "data=pd.read_csv('Average.csv')\n",
        "counts=data.groupby(['Team1','Team1_Status']).size().unstack(fill_value=0)\n",
        "counts1=data.groupby(['Team2','Team1_Status']).size().unstack(fill_value=0)\n",
        "counts2=data.groupby(['Venue','Team1_Status']).size().unstack(fill_value=0)\n",
        "\n",
        "status_count=counts.sum(axis=0)\n",
        "\n",
        "\n",
        "p_yes=counts['Yes']/status_count['Yes']\n",
        "p_no=counts['No']/status_count['No']--\n",
        "\n",
        "p_yes1=counts1['Yes']/status_count['Yes']\n",
        "p_no1=counts1['No']/status_count['No']\n",
        "\n",
        "p_yes2=counts2['Yes']/status_count['Yes']\n",
        "p_no2=counts2['No']/status_count['No']\n",
        "\n",
        "p_yestotal=status_count['Yes']/(status_count['Yes']+status_count['No'])\n",
        "p_nototal=status_count['No']/(status_count['Yes']+status_count['No'])\n",
        "\n",
        "result=pd.DataFrame({'Team1':counts.index,'Yes':counts['Yes'],'No':counts['No'],\n",
        "                     'Total_yes':status_count['Yes'],'Totoal_no':status_count['No'],\n",
        "                     'P(Yes|Team1)':p_yes,'P(No|Team1)':p_no})\n",
        "result=result.reset_index(drop=True)\n",
        "\n",
        "result1=pd.DataFrame({'Team2':counts1.index,'Yes':counts1['Yes'],'No':counts1['No'],\n",
        "                     'Total_yes':status_count['Yes'],'Totoal_no':status_count['No'],\n",
        "                     'P(Yes|Team2)':p_yes1,'P(No|Team2)':p_no1})\n",
        "result1=result1.reset_index(drop=True)\n",
        "\n",
        "result2=pd.DataFrame({'Venue':counts2.index,'Yes':counts2['Yes'],'No':counts2['No'],\n",
        "                     'Total_yes':status_count['Yes'],'Totoal_no':status_count['No'],\n",
        "                     'P(Yes|Venue)':p_yes2,'P(No|Venue)':p_no2})\n",
        "result2=result2.reset_index(drop=True)\n",
        "\n",
        "print(result)\n",
        "print(result1)\n",
        "print(result2)\n",
        "\n",
        "Team1=input('Enter Team1 name: ')\n",
        "Team2=input('Enter Team2 name: ')\n",
        "Venue=input('Enter Venue: ')\n",
        "\n",
        "res_filtered=result[(result['Team1']==Team1)]\n",
        "res1_filtered=result1[(result1['Team2']==Team2)]\n",
        "res2_filtered=result2[(result2['Venue']==Venue)]\n",
        "\n",
        "p_yesTeam1=res_filtered['P(Yes|Team1)'].values[0]\n",
        "p_yesTeam2=res1_filtered['P(Yes|Team2)'].values[0]\n",
        "p_yesVenue=res2_filtered['P(Yes|Venue)'].values[0]\n",
        "\n",
        "p_noTeam1=res_filtered['P(No|Team1)'].values[0]\n",
        "p_noTeam2=res1_filtered['P(No|Team2)'].values[0]\n",
        "p_noVenue=res2_filtered['P(No|Venue)'].values[0]\n",
        "\n",
        "\n",
        "p_yesfind=p_yesTeam1*p_yesTeam2*p_yesVenue*p_yestotal\n",
        "p_nofind=p_noTeam1*p_noTeam2*p_noVenue*p_nototal\n",
        "total = p_yesfind+p_nofind\n",
        "print(\"Total: \",total)\n",
        "while(math.isclose(total,1.0,abs_tol=0.001)==False):\n",
        "    print(\"Normalization\")\n",
        "    p_yesfind=p_yesfind/total\n",
        "    print(\"P(Yes|Find):\",p_yesfind)\n",
        "    p_nofind=p_nofind/total\n",
        "    print(\"P(No|Find):\",p_nofind)\n",
        "    total=p_yesfind+p_nofind\n",
        "    print('Total: ',total)\n",
        "\n",
        "if(p_yesfind>=p_nofind):\n",
        "    print(\"Team 1 can win\")\n",
        "else:\n",
        "    print(\"Team 1 will lose\")    \n"
      ],
      "metadata": {
        "id": "WLVlvfcgunrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 b Implement classification with using inbuilt libraries"
      ],
      "metadata": {
        "id": "stVG2ItWvWWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "data = pd.read_csv('Average.csv')\n",
        "data = pd.get_dummies(data, columns=['Team1', 'Team2', 'Venue'])\n",
        "print(data)\n",
        "\n",
        "df = pd.read_csv('Average.csv')\n",
        "X = pd.get_dummies(df.drop('Team1_Status', axis=1))\n",
        "print(X)\n",
        "y = df['Team1_Status']\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.drop('Team1_Status', axis=1), data['Team1_Status'], test_size=0.2, random_state=42)\n",
        "model = GaussianNB()\n",
        "model.fit(X, y)\n",
        "team1 = input(\"Enter Team 1: \")\n",
        "team2 = input(\"Enter Team 2: \")\n",
        "venue = input(\"Enter Venue: \")\n",
        "\n",
        "X_new = pd.DataFrame({'Team1_' + team1: [1], 'Team2_' + team2: [1], 'Venue_' + venue: [1]})\n",
        "X_new = X_new.reindex(columns=X.columns, fill_value=0)\n",
        "y_new = model.predict(X_new)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"The predicted Team1_Status is {y_new[0]}\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Confusion Matrix:\\n', confusion_mat)\n",
        "print('Classification Report:\\n', class_report)"
      ],
      "metadata": {
        "id": "Caax5y7hvZki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 a Implementation of Decision Tree using ID3 algorithm"
      ],
      "metadata": {
        "id": "VM7zle9PvhRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('PlayTennis.csv')\n",
        "\n",
        "X = df.drop('Play', axis=1)\n",
        "y = df['Play']\n",
        "\n",
        "le = LabelEncoder()\n",
        "X = X.apply(le.fit_transform)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100)\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(clf, filled=True, feature_names=X.columns, class_names=['0', '1'])\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "as4fuuMZvk76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 b Implementation of Decision Tree using C4.5 algorithm"
      ],
      "metadata": {
        "id": "kO1XUJQmv2dQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('PlayTennis.csv')\n",
        "x = df.drop('Play', axis=1)\n",
        "y = df['Play']\n",
        "\n",
        "le = LabelEncoder()\n",
        "x = x.apply(le.fit_transform)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(clf, filled=True, feature_names=x.columns, class_names=['0', '1'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "myWGWKFPv5zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 c  Implementation of Decision Tree using CART algorithm"
      ],
      "metadata": {
        "id": "t5fNXq4Vv8LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('PlayTennis.csv')\n",
        "\n",
        "x = df.drop('Play', axis=1)\n",
        "y = df['Play']\n",
        "\n",
        "le = LabelEncoder()\n",
        "x = x.apply(le.fit_transform)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "clf = DecisionTreeClassifier(criterion='gini', max_depth=None)\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(x_test)\n",
        "\n",
        "print(\"Accuracy is \", accuracy_score(y_test,y_pred)*100)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(clf, filled=True, feature_names=x.columns, class_names=['0', '1'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EuAO3MUHv-fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 a K – Means Clustering with library"
      ],
      "metadata": {
        "id": "YsmGZqjlwCHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv(\"Overrun.csv\")\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=0).fit(data_scaled)\n",
        "\n",
        "data[\"cluster\"] = kmeans.labels_\n",
        "\n",
        "plt.scatter(data.iloc[:, 0], data.iloc[:, 1], c=data[\"cluster\"])\n",
        "plt.xlabel(\"TV\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.title(\"K-means Clustering\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ADJbRL5ZwHI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5 b K – Means Clustering without library"
      ],
      "metadata": {
        "id": "rA7Kg84swJp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv(\"Overrun.csv\")\n",
        "X = np.array(data)\n",
        "K = 3\n",
        "max_iters = 100\n",
        "centroids = X[random.sample(range(len(X)), K)]\n",
        "for i in range(max_iters):\n",
        "    distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
        "    clusters = np.argmin(distances, axis=0)\n",
        "    for k in range(K):\n",
        "        centroids[k] = X[clusters == k].mean(axis=0)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=clusters)\n",
        "\n",
        "plt.title(\"K-means Clustering\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGBLFKT0wKGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 a Ensemble Learning:\n",
        "Bagging - Random Forest algorithm\n"
      ],
      "metadata": {
        "id": "CDwmakbRwQsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "df = pd.read_csv(\"url.csv\")\n",
        "\n",
        "X = df.iloc[:, 1:-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "print(\"Total No of Columns:\",X.shape[1])\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.3)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=3, random_state=42)\n",
        "rf.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = rf.predict(X_test)\n",
        "\n",
        "accuracy_value = metrics.accuracy_score(Y_test, Y_pred)\n",
        "print(\"\\nAccuracy: \", accuracy_value*100)\n",
        "\n",
        "test_data = [[0,0,1,5,0,0,0,0,0,1,1,1,0,0,1,0]]  # Example test data\n",
        "predictions = []\n",
        "print('\\n')\n",
        "for tree in rf.estimators_:\n",
        "    prediction = tree.predict(test_data)\n",
        "    predictions.append(prediction[0])\n",
        "    print(f\"Prediction of Tree {rf.estimators_.index(tree) + 1}: {'Not Malicious' if prediction[0]==0 else 'Malicious'}\")\n",
        "\n",
        "final_prediction = int(max(set(predictions), key=predictions.count))\n",
        "print('\\n')\n",
        "if final_prediction == 0:\n",
        "    print('It is not a Malicious URL')\n",
        "else:\n",
        "    print('It is a Malicious URL')\n",
        "\n"
      ],
      "metadata": {
        "id": "M1LdaeyKwRrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   6 b Ensemble Learning:\n",
        "Boosting - Adaptive Boosting\n"
      ],
      "metadata": {
        "id": "dAQISgSnwbEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "data = pd.read_csv(\"url.csv\")\n",
        "x = data.drop(columns=['Domain','Label'],axis=1)\n",
        "y = data['Label']\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.25)\n",
        "adb = AdaBoostClassifier(learning_rate=0.3)\n",
        "adb_model = adb.fit(X_train,Y_train)\n",
        "print(\"The accuracy of the model on validation set is\", adb_model.score(X_test,Y_test))  "
      ],
      "metadata": {
        "id": "UPMDDYLvwbYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 c Boosting – Gradient Boosting"
      ],
      "metadata": {
        "id": "-tBK-5-qwqJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "data = pd.read_csv('url.csv')\n",
        "\n",
        "X = data.drop(columns=['Domain','Label'],axis = 1)\n",
        "Y = data['Label']\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
        "GradBoost = GradientBoostingClassifier(init=tree_model, learning_rate=0.1, n_estimators=200)\n",
        "GradBoost.fit(X_train, Y_train)\n",
        "Y_pred_boost = GradBoost.predict(X_test)\n",
        "\n",
        "accuracy_boost = metrics.accuracy_score(Y_test, Y_pred_boost)\n",
        "print(\"Accuracy of Gradient Boosted model: \", accuracy_boost*100)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6aIK_vQRwrCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 d Boosting - LG Boosting"
      ],
      "metadata": {
        "id": "I0dkYlwYw0OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "data = pd.read_csv(\"url.csv\")\n",
        "x = data.drop(columns=['Domain','Label'],axis=1)\n",
        "y = data['Label']\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.25)\n",
        "lgb = LGBMClassifier(learning_rate=0.3)\n",
        "lgb_model = lgb.fit(X_train,Y_train)\n",
        "print(\"The accuracy of the model on validation set is\", lgb_model.score(X_test,Y_test)*100)  "
      ],
      "metadata": {
        "id": "RGvLjATBw23o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 e Boosting - Categorical Boosting"
      ],
      "metadata": {
        "id": "zTVz2pn7w3W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import catboost as ctb\n",
        "\n",
        "data = pd.read_csv(\"url.csv\")\n",
        "x = data.drop(columns=['Domain','Label'],axis=1)\n",
        "y = data['Label']\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.25)\n",
        "catb = ctb.CatBoostClassifier()\n",
        "catb_model = catb.fit(X_train,Y_train)\n",
        "print(\"The accuracy of the model on validation set is\", catb_model.score(X_test,Y_test)*100)  "
      ],
      "metadata": {
        "id": "j2-5c_TPw6H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 Support Vector Machine"
      ],
      "metadata": {
        "id": "ikbaCR-gw6ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "url_data = pd.read_csv('url.csv')\n",
        "\n",
        "# Separate the features and target variable\n",
        "X = url_data.drop(columns=['Domain','Label'],axis=1)\n",
        "y = url_data['Label']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM model\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.xticks([0, 1], ['Benign', 'Malicious'])\n",
        "plt.yticks([0, 1], ['Benign', 'Malicious'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V4h6VeGEw9cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8 Reinforcement Learning: \n",
        "Q-learning\n"
      ],
      "metadata": {
        "id": "6s_yvseYw95d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "# Define the Q-learning function\n",
        "def q_learning(env, num_episodes, alpha, gamma, epsilon):\n",
        "    # Initialize the Q-table to zeros\n",
        "    Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    \n",
        "    # Loop over episodes\n",
        "    for episode in range(num_episodes):\n",
        "        # Reset the environment\n",
        "        state = env.reset()\n",
        "        \n",
        "        # Initialize the total reward for this episode\n",
        "        total_reward = 0\n",
        "        \n",
        "        # Loop over time steps in this episode\n",
        "        done = False\n",
        "        while not done:\n",
        "            # Choose an action using an epsilon-greedy policy\n",
        "            if np.random.random() < epsilon:\n",
        "                action = env.action_space.sample()  # explore\n",
        "            else:\n",
        "                action = np.argmax(Q[state])  # exploit\n",
        "            \n",
        "            # Take the chosen action and observe the next state and reward\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            \n",
        "            # Update the Q-table\n",
        "            Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n",
        "            \n",
        "            # Update the total reward\n",
        "            total_reward += reward\n",
        "            \n",
        "            # Update the state for the next iteration\n",
        "            state = next_state\n",
        "        \n",
        "        # Print the total reward for this episode\n",
        "        print(f\"Episode {episode + 1}: Total reward = {total_reward}\")\n",
        "        \n",
        "    return Q\n",
        "\n",
        "\n",
        "# Create the environment\n",
        "env = gym.make('Taxi-v3')\n",
        "\n",
        "# Set the hyperparameters\n",
        "num_episodes = 1000\n",
        "alpha = 0.1\n",
        "gamma = 0.99\n",
        "epsilon = 0.1\n",
        "\n",
        "# Run the Q-learning algorithm\n",
        "Q = q_learning(env, num_episodes, alpha, gamma, epsilon)\n",
        "\n",
        "# Close the environment\n",
        "env.close()\n"
      ],
      "metadata": {
        "id": "TG4KbwPbxA6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9 Multi Layer Perceptron"
      ],
      "metadata": {
        "id": "juJZ3aMSxBZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases randomly\n",
        "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
        "        self.bias1 = np.random.randn(hidden_size)\n",
        "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
        "        self.bias2 = np.random.randn(output_size)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Calculate the hidden layer output\n",
        "        self.hidden_output = self.sigmoid(np.dot(X, self.weights1) + self.bias1)\n",
        "\n",
        "        # Calculate the output layer output\n",
        "        self.output = self.sigmoid(np.dot(self.hidden_output, self.weights2) + self.bias2)\n",
        "\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        # Calculate the derivative of the cost function with respect to the output\n",
        "        d_output = (self.output - y) * self.output * (1 - self.output)\n",
        "\n",
        "        # Calculate the derivative of the cost function with respect to the hidden layer\n",
        "        d_hidden_output = np.dot(d_output, self.weights2.T) * self.hidden_output * (1 - self.hidden_output)\n",
        "\n",
        "        # Update the weights and biases\n",
        "        self.weights2 -= learning_rate * np.dot(self.hidden_output.T, d_output)\n",
        "        self.bias2 -= learning_rate * np.sum(d_output, axis=0)\n",
        "        self.weights1 -= learning_rate * np.dot(X.T, d_hidden_output)\n",
        "        self.bias1 -= learning_rate * np.sum(d_hidden_output, axis=0)\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for i in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            cost = np.mean((y - output) ** 2)\n",
        "            self.backward(X, y, learning_rate)\n",
        "            # if i % 100 == 0:\n",
        "        print(f\"Epoch: {i}, Cost: {cost:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return np.round(output)\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "mlp = MLP(2, 4, 1)\n",
        "mlp.train(X, y, 10000, 0.1)\n",
        "\n",
        "# Test the MLP on new data\n",
        "test_input = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "test_output = mlp.predict(test_input)\n",
        "\n",
        "print(test_output)"
      ],
      "metadata": {
        "id": "N2kEZDjixB1P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}